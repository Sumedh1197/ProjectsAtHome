{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation system using ALS algorithm in Spark (Explicit feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have utilised the movielens (100k) dataset for building the recommendation system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from pyspark.sql.functions import col, avg\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_1= SparkSession.builder.appName('Recommender_system').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading our CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|     31|   2.5|1260759144|\n",
      "|     1|   1029|   3.0|1260759179|\n",
      "|     1|   1061|   3.0|1260759182|\n",
      "|     1|   1129|   2.0|1260759185|\n",
      "|     1|   1172|   4.0|1260759205|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark_1.read.csv('ratings.csv',header=True,inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not be using the timestamp column for our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of distinct users\n",
    "df.select('userId').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS works well with sparse datasets.\n",
    "dividing the number of ratings present in the matrix by the product of users and movies in the matrix and subtracting that from 1 will give us the sparsity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie ratings dataframe is  98.36% empty.\n"
     ]
    }
   ],
   "source": [
    "num= df.select('rating').count()\n",
    "user_no= df.select('userId').distinct().count()\n",
    "movie_no= df.select('movieId').distinct().count()\n",
    "\n",
    "sparsity= (1.0-(num*1.0)/(user_no*movie_no))*100\n",
    "\n",
    "print(\"The movie ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|     1|   20|\n",
      "|     2|   76|\n",
      "|     3|   51|\n",
      "|     4|  204|\n",
      "|     5|  100|\n",
      "|     6|   44|\n",
      "|     7|   88|\n",
      "|     8|  116|\n",
      "|     9|   45|\n",
      "|    10|   46|\n",
      "|    11|   38|\n",
      "|    12|   61|\n",
      "|    13|   53|\n",
      "|    14|   20|\n",
      "|    15| 1700|\n",
      "|    16|   29|\n",
      "|    17|  363|\n",
      "|    18|   51|\n",
      "|    19|  423|\n",
      "|    20|   98|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let us see how many movies which userId had rated\n",
    "df.groupBy('userId').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average num ratings per movie: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|11.030664019413193|\n",
      "+------------------+\n",
      "\n",
      "Avg num ratings per user: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|149.03725782414307|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avg num ratings per movie\n",
    "print(\"Average num ratings per movie: \")\n",
    "df.groupBy(\"movieId\").count().select(avg(\"count\")).show()\n",
    "\n",
    "\n",
    "# Avg num ratings per users\n",
    "print(\"Avg num ratings per user: \")\n",
    "df.groupBy(\"userId\").count().select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg sum of rating given by users is: \n",
      "+----------+\n",
      "|avg(count)|\n",
      "+----------+\n",
      "|   10000.4|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Average sum of rating given by user \n",
    "print('The avg sum of rating given by users is: ')\n",
    "df.groupBy('rating').count().select(avg('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the schema of our dataframe \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: double]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping timestamp column as it is not necessary for our application \n",
    "df.drop('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Spark ML implements alternating least squares (ALS) and we will use collaborative filtering for our application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing data\n",
    "(train, test) = df.randomSplit([0.7, 0.3], seed = 567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALS"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als = ALS(maxIter=10,regParam=0.1,rank=5,userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.9245592708112048\n"
     ]
    }
   ],
   "source": [
    "#Evaluating our model performance using root mean squared error \n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|   380|    463|   3.0| 968949106| 2.9645996|\n",
      "|   242|    463|   4.0| 956685706| 3.9067533|\n",
      "|   440|    471|   3.0| 835337519| 3.0974295|\n",
      "|   452|    471|   3.0| 976422396|  3.473732|\n",
      "|   299|    471|   4.5|1344186741|  4.303039|\n",
      "|    15|    471|   3.0|1166586067| 2.7023463|\n",
      "|   358|    471|   5.0| 957479605| 3.6117182|\n",
      "|   502|    471|   4.0| 861322541| 4.2407923|\n",
      "|   537|    471|   5.0| 879502608| 3.7298114|\n",
      "|   514|    471|   4.0| 853893788|  3.761124|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make the output more readable and detailed. I will read the movies, tags and links file into separate dataframes and join them on their common movie ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df= spark_1.read.csv('datasets_66613_153886_movies.csv', inferSchema=True,header=True)\n",
    "movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- imdbId: integer (nullable = true)\n",
      " |-- tmdbId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links_df= spark_1.read.csv('links.csv', inferSchema=True,header=True)\n",
    "links_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags_df= spark_1.read.csv('tags.csv', inferSchema=True,header=True)\n",
    "tags_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df1= tags_df.drop('userId','timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+----------------+----------+\n",
      "|userId|               title|              genres|             tag|prediction|\n",
      "+------+--------------------+--------------------+----------------+----------+\n",
      "|   372|Dirty Dancing (1987)|Drama|Musical|Rom...|   rich families|  4.292309|\n",
      "|   372|Dirty Dancing (1987)|Drama|Musical|Rom...|musical parodies|  4.292309|\n",
      "|   372|Dirty Dancing (1987)|Drama|Musical|Rom...|           music|  4.292309|\n",
      "|   372|Dirty Dancing (1987)|Drama|Musical|Rom...|    girlie movie|  4.292309|\n",
      "|   372|Dirty Dancing (1987)|Drama|Musical|Rom...|           dance|  4.292309|\n",
      "|   372|Dirty Dancing (1987)|Drama|Musical|Rom...|    80's classic|  4.292309|\n",
      "|    15|Dirty Dancing (1987)|Drama|Musical|Rom...|   rich families| 1.4738356|\n",
      "|    15|Dirty Dancing (1987)|Drama|Musical|Rom...|musical parodies| 1.4738356|\n",
      "|    15|Dirty Dancing (1987)|Drama|Musical|Rom...|           music| 1.4738356|\n",
      "|    15|Dirty Dancing (1987)|Drama|Musical|Rom...|    girlie movie| 1.4738356|\n",
      "+------+--------------------+--------------------+----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.join(movies_df,'movieId').join(tags_df1,'movieId').select('userId','title','genres','tag','prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us obtain recommendations for a particular user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+------+----------+\n",
      "|userId|               title|              genres|tmdbId|prediction|\n",
      "+------+--------------------+--------------------+------+----------+\n",
      "|   514|Hudsucker Proxy, ...|              Comedy| 11934|  3.761124|\n",
      "|   514|     Candyman (1992)|     Horror|Thriller|  9529| 3.1466775|\n",
      "|   514|Sword in the Ston...|Animation|Childre...|  9078| 3.2427876|\n",
      "|   514|Back to the Futur...|Adventure|Comedy|...|   105| 3.8019257|\n",
      "|   514|Groundhog Day (1993)|Comedy|Fantasy|Ro...|   137| 3.7863579|\n",
      "+------+--------------------+--------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+--------------------+--------------------+------+----------+\n",
      "|userId|               title|              genres|tmdbId|prediction|\n",
      "+------+--------------------+--------------------+------+----------+\n",
      "|    60|Sea Inside, The (...|               Drama|  1913|  4.585308|\n",
      "|    60|      Gattaca (1997)|Drama|Sci-Fi|Thri...|   782| 4.0912075|\n",
      "|    60|          Big (1988)|Comedy|Drama|Fant...|  2280|  3.810635|\n",
      "|    60|  Taxi Driver (1976)|Crime|Drama|Thriller|   103|  4.786331|\n",
      "|    60|Laputa: Castle in...|Action|Adventure|...| 10515| 4.3595204|\n",
      "+------+--------------------+--------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for_514= predictions.filter(col('userId')==514).join(movies_df,'movieId').join(links_df,'movieId').select('userId','title','genres','tmdbId','prediction')\n",
    "for_514.show(5)\n",
    "\n",
    "for_60= predictions.filter(col('userId')==60).join(movies_df,'movieId').join(links_df,'movieId').select('userId','title','genres','tmdbId','prediction')\n",
    "for_60.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us obtain top 10 movie recommendations for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[3414, 5.341756]...|\n",
      "|   463|[[67504, 5.396364...|\n",
      "|   496|[[3414, 6.153739]...|\n",
      "|   148|[[67504, 5.622106...|\n",
      "|   540|[[8530, 6.8435507...|\n",
      "|   392|[[92494, 5.321902...|\n",
      "|   243|[[67504, 5.354881...|\n",
      "|   623|[[67504, 6.065434...|\n",
      "|    31|[[67504, 5.406029...|\n",
      "|   516|[[83318, 5.212477...|\n",
      "|   580|[[67504, 5.266863...|\n",
      "|   251|[[79824, 5.674916...|\n",
      "|   451|[[8535, 5.69648],...|\n",
      "|    85|[[3414, 6.5535035...|\n",
      "|   137|[[67504, 5.350032...|\n",
      "|    65|[[40412, 5.993492...|\n",
      "|   458|[[3414, 5.0007744...|\n",
      "|   481|[[67504, 6.33814]...|\n",
      "|    53|[[3181, 6.2962766...|\n",
      "|   255|[[67504, 6.233779...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userReco = model.recommendForAllUsers(10)\n",
    "userReco.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us obtain top 10 user recommendations for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   1580|[[113, 5.158268],...|\n",
      "|   5300|[[154, 5.5862513]...|\n",
      "|   6620|[[545, 4.897958],...|\n",
      "|   7340|[[228, 5.1227913]...|\n",
      "|  54190|[[261, 5.6989427]...|\n",
      "|    471|[[70, 4.740661], ...|\n",
      "|   1591|[[113, 4.2510023]...|\n",
      "|   4101|[[4, 5.6551213], ...|\n",
      "|   1342|[[401, 4.211051],...|\n",
      "|   2122|[[46, 3.3270643],...|\n",
      "|   2142|[[112, 4.729786],...|\n",
      "|   7982|[[113, 5.2086515]...|\n",
      "|  44022|[[46, 5.17425], [...|\n",
      "| 141422|[[228, 3.079749],...|\n",
      "|    463|[[46, 5.2227902],...|\n",
      "|    833|[[113, 1.2288729]...|\n",
      "|   5803|[[113, 3.0634222]...|\n",
      "|   7833|[[113, 4.906775],...|\n",
      "| 160563|[[145, 4.045021],...|\n",
      "|   3794|[[484, 4.5837765]...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieReco = model.recommendForAllItems(10)\n",
    "movieReco.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will obtain the movie website using the tmdbId which acts as an index for 'https://www.themoviedb.org/movie/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hudsucker Proxy, The (1994)\n",
      "Candyman (1992)\n"
     ]
    }
   ],
   "source": [
    "import webbrowser\n",
    "link= 'https://www.themoviedb.org/movie/'\n",
    "for movie in for_514.take(2):\n",
    "    URL= link+ str(movie.tmdbId)\n",
    "    print(movie.title)\n",
    "    webbrowser.open(URL)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For userId 514 we have extracted two recommendations and after we run this block we will be redirected towards the movie websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANK YOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
